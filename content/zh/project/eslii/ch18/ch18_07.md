---
title: 18.7 Feature Assessment and the Multiple-Testing Problem
summary: >
  第 683-693 页。

date: 2022-04-01T11:00:00+08:00
draft: true 
math: true

type: book
weight: 1807

authors: ["Butters"]
tags: ["译文"]
categories: ["统计学习基础（译注）"]

---

In the first part of this chapter we discuss prediction models in the p ≫ N
setting. Here we consider the more basic problem of assessing the signif-
icance of each of the p features. Consider the protein mass spectrometry
example of Section 18.4.1. In that problem, the scientist might not be inter-
ested in predicting whether a given patient has prostate cancer. Rather the
goal might be to identify proteins whose abundance differs between nor-
mal and cancer samples, in order to enhance understanding of the disease
and suggest targets for drug development. Thus our goal is to assess the
significance of individual features. This assessment is usually done without
the use of a multivariate predictive model like those in the first part of this
chapter. The feature assessment problem moves our focus from prediction
to the traditional statistical topic of multiple hypothesis testing. For the
remainder of this chapter we will use M instead of p to denote the number
of features, since we will frequently be referring to p-values.

<table>
 <tr>
  <th></th>
  <th colspan="4">Normal</td>
  <th colspan="4">Radiation Sensitive</td>
 </tr>
 <tr>
  <td>Gene 1</td>
  <td>7.85</td><td>29.74</td><td>29.50</td><td>...</td>
  <td>17.20</td><td>-50.75</td><td>-18.89</td><td>...</td>
 </tr>
 <tr>
  <td>Gene 2</td>
  <td>15.44</td><td>2.70</td><td>19.37</td><td>...</td>
  <td>6.57</td><td>-7.41</td><td>79.18</td><td>...</td>
 </tr>
 <tr>
  <td>Gene 3</td>
  <td>-1.79</td><td>15.52</td><td>-3.13</td><td>...</td>
  <td>-8.32</td><td>12.64</td><td>4.75</td><td>...</td>
 </tr>
 <tr>
  <td>Gene 4</td>
  <td>-11.74</td><td>22.35</td><td>-36.11</td><td>...</td>
  <td>-52.17</td><td>7.24</td><td>-2.32</td><td>...</td>
 </tr>
 <tr>
  <td>...</td>
  <td></td>
  <td></td>
  <td></td>
  <td>...</td>
  <td></td>
  <td></td>
  <td></td>
  <td>...</td>
 </tr>
 <tr>
  <td>Gene 12625</td>
  <td>-14.09</td><td>32.77</td><td>57.78</td><td>...</td>
  <td>-32.84</td><td>24.09</td><td>-101.44</td><td>...</td>
 </tr>
 <caption>
** 表 18.4**：
</caption>
</table>

Consider, for example, the microarray data in Table 18.4, taken from a
study on the sensitivity of cancer patients to ionizing radiation treatment
(Rieger et al., 2004). Each row consists of the expression of genes in 58
patient samples: 44 samples were from patients with a normal reaction, and
14 from patients who had a severe reaction to radiation. The measurements
were made on oligo-nucleotide microarrays. The object of the experiment
was to find genes whose expression was different in the radiation sensitive
group of patients. There are M = 12, 625 genes altogether; the table shows
the data for some of the genes and samples for illustration.

To identify informative genes, we construct a two-sample t-statistic for
each gene.

$$t_j = \frac{\bar{x}\_{2j} - \bar{x}\_{1j}}{\text{se}\_j} \tag{18.38}$$

where $\bar{x}\_{kj}=\sum_{i\in{C_\ell}}x_{ij}/N_\ell$. Here C ℓ are the indices of the N ℓ samples in
group ℓ, where ℓ = 1 is the normal group and ℓ = 2 is the sensitive group.
The quantity se j is the pooled within-group standard error for gene j:

$$\begin{gather}
\text{se}\_j = \hat{\sigma}\_j \sqrt{\frac{1}{N_1} + \frac{1}{N_2}} \\\\
\hat{\sigma}\_j^2 = \frac{1}{N_1+N_2-2} \left(
  \sum_{i \in C_1 } (x_{ij} - \bar{x}\_{1j})^2 +
  \sum_{i \in C_2 } (x_{ij} - \bar{x}\_{2j})^2 \right)
\end{gather}$$
$$\tag{18.39}$$

{{< figure
  id="f1818"
  src="https://public.guansong.wang/eslii/ch18/eslii_fig_18_18.png"
  title="**图 18.18**：Radiation sensitivity microarray example. A histogram of the 12, 625 t-statistics comparing the radiation-sensitive versus insensitive groups. Overlaid in blue is the histogram of the t-statistics from 1000 permutations of the sample labels."
>}}

A histogram of the 12,625 t-statistics is shown in orange in Figure 18.18,
ranging in value from −4.7 to 5.0. If the t j values were normally distributed
we could consider any value greater than two in absolute value to be sig-
nificantly large. This would correspond to a significance level of about 5%.
Here there are 1189 genes with |t j | ≥ 2. However with 12,625 genes we
would expect many large values to occur by chance, even if the group-
ing is unrelated to any gene. For example, if the genes were independent
(which they are surely not), the number of falsely significant genes would
have a binomial distribution with mean 12, 625 · 0.05 = 631.3 and standard
deviation 24.5; the actual 1189 is way out of range.

How do we assess the results for all 12,625 genes? This is called the mul-
tiple testing problem. We can start as above by computing a p-value for
each gene. This can be done using the theoretical t-distribution probabil-
ities, which assumes the features are normally distributed. An attractive
alternative approach is to use the permutation distribution, since it avoids
assumptions  about the distribution of the data. We compute (in principle)
all $K=\binom{58}{14}$ permutations of the sample labels, and for each permutation
k compute the t-statistics t kj . Then the p-value for gene j is

$$p_j = \frac{1}{K} \sum_{k=1}^K I(|t_j^k| > |t_j|) \tag{18.40}$$

Of course, $\binom{58}{14}$ is a large number (around 10 ) and so we can’t enumer-
ate all of the possible permutations. Instead we take a random sample of
the possible permutations; here we took a random sample of K = 1000
permutations.

To exploit the fact that the genes are similar (e.g., measured on the
same scale), we can instead pool the results for all genes in computing the
p-values.

$$p_j = \frac{1}{MK} \sum_{j'=1}^M \sum_{k=1}^K I(|t_{j'}^k| > |t_j|) \tag{18.41}$$

This also gives more granular p-values than does (18.40), since there many
more values in the pooled null distribution than there are in each individual
null distribution.

Using this set of p-values, we would like to test the hypotheses:

$$\begin{gather}
H_{0j} = \text{treatment has no effect on gene } j \\\\
versus \\\\
H_{1j} = \text{treatment has an effect on gene } j
\end{gather}\tag{18.42}$$

for all j = 1, 2, . . . , M . We reject H 0j at level α if p j < α. This test has
type-I error equal to α; that is, the probability of falsely rejecting H 0j is α.

Now with many tests to consider, it is not clear what we should use
as an overall measure of error. Let A j be the event that H 0j is falsely
rejected; by definition Pr(A j ) = α. The family-wise error rate (FWER)
is the probability of at least one false rejection, and is a commonly used
overall measure of error. In detail, if A = ∪ M j=1 A j is the event of at least
one false rejection, then the FWER is Pr(A). Generally Pr(A) ≫ α for
large M , and depends on the correlation between the tests. If the tests are
independent each with type-I error rate α, then the family-wise error rate
of the collection of tests is (1 − (1 − α) M ). On the other hand, if the tests
have positive dependence, that is Pr(A j |A k ) > Pr(A j ), then the FWER
will be less than (1 − (1 − α) M ). Positive dependence between tests often
occurs in practice, in particular in genomic studies.

One of the simplest approaches to multiple testing is the Bonferroni
method. It makes each individual test more stringent, in order to make the
FWER equal to at most α: we reject H 0j if p j < α/M . It is easy to show
that the resulting FWER is ≤ α (Exercise 18.16). The Bonferroni method
can be useful if M is relatively small, but for large M it is too conservative,
that is, it calls too few genes significant.

In our example, if we test at level say α = 0.05, then we must use the
threshold 0.05/12, 625 = 3.9×10 −6 . None of the 12, 625 genes had a p-value
this small.

There are variations to this approach that adjust the individual p-values
to achieve an FWER of at most α, with some approaches avoiding the
assumption of independence; see, e.g., Dudoit et al. (2002b).

### 18.7.1 The False Discovery Rate

A different approach to multiple testing does not try to control the FWER,
but focuses instead on the proportion of falsely significant genes. As we will
see, this approach has a strong practical appeal.

|             | Called Not Significant | Called Significant | Total |
|-------------|:----------------------:|:------------------:|:-----:|
| $H_0$ True  | $U$                    | $V$                | $M_0$ |
| $H_0$ False | $T$                    | $S$                | $M_1$ |
| Total       | $M-R$                  | $R$                | $M$   |

**表 18.5**：Possible outcomes from M hypothesis tests. Note that V is the
number of false-positive tests; the type-I error rate is E(V )/M 0 . The type-II error rate is E(T )/M 1 , and the power is 1 − E(T )/M 1 .

Table 18.5 summarizes the theoretical outcomes of M hypothesis tests.
Note that the family-wise error rate is Pr(V ≥ 1). Here we instead focus
on the false discovery rate

$$\text{FDR} = \operatorname{E}(V/R) \tag{18.43}$$

In the microarray setting, this is the expected proportion of genes that
are incorrectly called significant, among the R genes that are called signif-
icant. The expectation is taken over the population from which the data
are generated. Benjamini and Hochberg (1995) first proposed the notion of
false discovery rate, and gave a testing procedure (Algorithm 18.2) whose
FDR is bounded by a user-defined level α. The Benjamini–Hochberg (BH)
procedure is based on p-values; these can be obtained from an asymptotic
approximation to the test statistic (e.g., Gaussian), or a permutation dis-
tribution, as is done here.

----------
#### 算法 18.2：Benjamini–Hochberg (BH) Method.
1. Fix the false discovery rate α and let p (1) ≤ p (2) ≤ · · · ≤ p (M ) denote the ordered p-values
2. Define
   $$L = \max \left\\{ j: p_{(j)} < \alpha \cdot \frac{j}{M} \right\\} \tag{18.44}$$
3. Reject all hypotheses H 0j for which p j ≤ p (L) , the BH rejection threshold.
----------

If the hypotheses are independent, Benjamini and Hochberg (1995) show
that regardless of how many null hypotheses are true and regardless of the
distribution of the p-values when the null hypothesis is false, this procedure
has the property

$$\text{FDR} \leq \frac{M_0}{M}\alpha \leq \alpha \tag{18.45}$$

{{< figure
  id="f1819"
  src="https://public.guansong.wang/eslii/ch18/eslii_fig_18_19.png"
  title="**图 18.19**：Microarray example continued. Shown is a plot of the ordered p-values p (j) and the line 0.15 · (j/12, 625), for the Benjamini–Hochberg method. The largest j for which the p-value p (j) falls below the line, gives the BH threshold. Here this occurs at j = 11, indicated by the vertical line. Thus the BH method calls significant the 11 genes (in red) with smallest p-values."
>}}

For illustration we chose α = 0.15. Figure 18.19 shows a plot of the or-
dered p-values p (j) , and the line with slope 0.15/12625.

Starting at the left and moving right, the BH method finds the last time
that the p-values fall below the line. This occurs at j = 11, so we reject
the 11 genes with smallest p-values. Note that the cutoff occurs at the 11th
smallest p-value, 0.00012, and the 11th largest of the values |t j | is 4.101
Thus we reject the 11 genes with |t j | ≥ 4.101.

From our brief description, it is not clear how the BH procedure works;
that is, why the corresponding FDR is at most 0.15, the value used for α.
Indeed, the proof of this fact is quite complicated (Benjamini and Hochberg,
1995).

A more direct way to proceed is a plug-in approach. Rather than starting
with a value for α, we fix a cut-point for our t-statistics, say the value
4.101 that appeared above. The number of observed values |t j | equal or
greater than 4.101 is 11. The total number of permutation values |t kj | equal
or greater than 4.101 is 1518, for an average of 1518/1000 = 1.518 per
permutation. Thus a direct estimate of the false discovery rate is FDR
1.518/11 ≈ 14%. Note that 14% is approximately equal to the value of
α = 0.15 used above (the difference is due to discreteness). This procedure
is summarized in Algorithm 18.3. To recap:

The plug-in estimate of FDR of Algorithm 18.3 is equivalent to the BH
procedure of Algorithm 18.2, using the permutation p-values (18.40).

----------
#### 算法 18.3：The Plug-in Estimate of the False Discovery Rate.
1. Create K permutations of the data, producing t-statistics t kj for features j = 1, 2, . . . , M and permutations k = 1, 2, . . . , K.
2. For a range of values of the cut-point C, let
   $$\begin{gather}
   R_\text{obs} = \sum_{j=1}^M I(|t_j| > C) \\\\
   \widehat{\operatorname{E}(V)} = \frac{1}{K} \sum_{j=1}^M \sum_{k=1}^K I(|t_j^k|>C)
   \end{gather}\tag{18.46}$$
3. Estimate the FDR by $\widehat{\text{FDR}}=\widehat{\operatorname{E}(V)}/R_\text{obs}$
----------

This correspondence between the BH method and the plug-in estimate is
not a coincidence. Exercise 18.17 shows that they are equivalent in general.
Note that this procedure makes no reference to p-values at all, but rather
works directly with the test statistics.

The plug-in estimate is based on the approximation

$$\operatorname{E}(V/R) \approx \frac{\operatorname{E}(V)}{\operatorname{E}(R)} \tag{18.47}$$

and in general FDR is a consistent estimate of FDR (Storey, 2002; Storey et
al., 2004). Note that the numerator E(V[ ) actually estimates (M/M 0 )E(V ),
since the permutation distribution uses M rather M 0 null hypotheses.
Hence if an estimate of M 0 is available, a better estimate of FDR can be
[ Exercise 18.19 shows a way to estimate M 0 .obtained from ( M̂ 0 /M ) · FDR.
The most conservative (upwardly biased) estimate of FDR uses M 0 = M .
Equivalently, an estimate of M 0 can be used to improve the BH method,
through relation (18.45).

The reader might be surprised that we chose a value as large as 0.15 for
α, the FDR bound. We must remember that the FDR is not the same as
type-I error, for which 0.05 is the customary choice. For the scientist, the
false discovery rate is the expected proportion of false positive genes among
the list of genes that the statistician tells him are significant. Microarray
experiments with FDRs as high as 0.15 might still be useful, especially if
they are exploratory in nature.

### 18.7.2 Asymmetric Cutpoints and the SAM Procedure

In the testing methods described above, we used the absolute value of the
test statistic t j , and hence applied the same cut-points to both positive and
negative values of the statistic. In some experiments, it might happen that
most or all of the differentially expressed genes change in the positive direc-
tion (or all in the negative direction). For this situation it is advantageous
to derive separate cut-points for the two cases.

{{< figure
  id="f1819"
  src="https://public.guansong.wang/eslii/ch18/eslii_fig_18_19.png"
  title="**图 18.20**：SAM plot for the radiation sensitivity microarray data. On the vertical axis we have plotted the ordered test statistics, while the horizontal axis shows the expected order statistics of the test statistics from permutations of the data. Two lines are drawn, parallel to the 45 ◦ line, ∆ units away from it. Starting at the origin and moving to the right, we find the first place that the genes leave the band. This defines the upper cut-point C hi and all genes beyond that point are called significant (marked in red). Similarly we define a lower cutpoint C low . For the particular value of ∆ = 0.71 in the plot, no genes are called significant in the bottom left."
>}}

The significance analysis of microarrays (SAM) approach offers a way of
doing this. The basis of the SAM method is shown in Figure 18.20. On the
vertical axis we have plotted the ordered test statistics t (1) ≤ t (2) ≤ · · · ≤
t (M ) , while the horizontal axis shows the expected order statistics from the P K
permutations of the data: t̃ (j) = (1/K) k=1 t k (j) , where t k (1) ≤ t k (2) ≤ · · · ≤
t k (M ) are the ordered test statistics from permutation k.

Two lines are drawn, parallel to the 45 ◦ line, ∆ units away. Starting at
the origin and moving to the right, we find the first place that the genes
leave the band. This defines the upper cutpoint C hi and all genes beyond
that point are called significant (marked red). Similarly we find the lower
cutpoint C low for genes in the bottom left corner. Thus each value of the
tuning parameter ∆ defines upper and lower cutpoints, and the plug-in
estimate FDR[ for each of these cutpoints is estimated as before. Typically
a range of values of ∆ and associated FDR[ values are computed, from which
a particular pair are chosen on subjective grounds.

The advantage of the SAM approach lies in the possible asymmetry of
the cutpoints. In the example of Figure 18.20, with ∆ = 0.71 we obtain
11 significant genes; they are all in the upper right. The data points in the
bottom left never leave the band, and hence C low = −∞. Hence for this
value of ∆, no genes are called significant on the left (negative) side. We
do not impose symmetry on the cutpoints, as was done in Section 18.7.1,
as there is no reason to assume similar behavior at the two ends.

There is some similarity between this approach and the asymmetry possi-
ble with likelihood-ratio tests. Suppose we have a log-likelihood ℓ 0 (t j ) under
the null-hypothesis of no effect, and a log-likelihood ℓ(t j ) under the alterna-
tive. Then a likelihood ratio test amounts to rejecting the null-hypothesis
if

$$\ell(t_j) - \ell_0(t_j) > \Delta \tag{18.48}$$

for some ∆. Depending on the likelihoods, and particularly their relative
values, this can result in a different threshold for t j than for −t j . The SAM
procedure rejects the null-hypothesis if

$$|t_{(j)} - \tilde{t}\_{(j)}| > \Delta \tag{18.49}$$

Again, the threshold for each t (j) depends on the corresponding value of
the null value t̃ (j) .

### 18.7.3 A Bayesian Interpretation of the FDR :scream:

There is an interesting Bayesian view of the FDR, developed in Storey
(2002) and Efron and Tibshirani (2002). First we need to define the positive
false discovery rate (pFDR) as

$$\text{pFDR} = \operatorname{E} \left[ \frac{V}{R} \Big| R>0 \right]\tag{18.50}$$

The additional term positive refers to the fact that we are only interested
in estimating an error rate where positive findings have occurred. It is
this slightly modified version of the FDR that has a clean Bayesian inter-
pretation. Note that the usual FDR [expression (18.43)] is not defined if
Pr(R = 0) > 0.

Let Γ be a rejection region for a single test; in the example above we used
Γ = (−∞, −4.10) ∪ (4.10, ∞). Suppose that M identical simple hypothe-
sis tests are performed with the i.i.d. statistics t 1 , . . . , t M and rejection
region Γ. We define a random variable Z j which equals 0 if the jth null
hypothesis is true, and 1 otherwise. We assume that each pair (t j , Z j ) are
i.i.d random variables with

$$t_j | Z_j \sim (1-Z_j) \cdot F_0 + Z_j \cdot F_1 \tag{18.51}$$

for some distributions F 0 and F 1 . This says that each test statistic t j comes
from one of two distributions: F 0 if the null hypothesis is true, and F 1
otherwise. Letting Pr(Z j = 0) = π 0 , marginally we have:

$$t_j \sim \pi_0 \cdot F_0 + (1-\pi_0) \cdot F_1 \tag{18.52}$$

Then it can be shown (Efron et al., 2001; Storey, 2002) that

$$\text{pFDR}(\Gamma) = \operatorname{Pr}(Z_j=0 | t_j \in \Gamma) \tag{18.53}$$

Hence under the mixture model (18.51), the pFDR is the posterior proba-
bility that the null hypothesis it true, given that test statistic falls in the
rejection region for the test; that is, given that we reject the null hypothesis
(Exercise 18.20).

The false discovery rate provides a measure of accuracy for tests based
on an entire rejection region, such as |t j | ≥ 2. But if the FDR of such a test
is say 10%, then a gene with say t j = 5 will be more significant than a gene
with t j = 2. Thus it is of interest to derive a local (gene-specific) version
of the FDR. The q-value (Storey, 2003) of a test statistic t j is defined to
be the smallest FDR over all rejection regions that reject t j . That is, for
symmetric rejection regions, the q-value for t j = 2 is defined to be the
FDR for the rejection region Γ = {−(∞, −2) ∪ (2, ∞)}. Thus the q-value
for t j = 5 will be smaller than that for t j = 2, reflecting the fact that t j = 5
is more significant than t j = 2. The local false discovery rate (Efron and
Tibshirani, 2002) at t = t 0 is defined to be

$$\operatorname{Pr}(Z_j = 0 | t_j = t_0) \tag{18.54}$$

This is the (positive) FDR for an infinitesimal rejection region surrounding
the value t j = t 0 .