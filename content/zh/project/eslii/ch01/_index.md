---
title: 1 序言
summary: >
  第 1-8 页。对本书内容概括性地介绍，几个实际应用的例子，章节的逻辑结构，等等。

date: 2018-08-29T16:21:07+08:00
lastmod: 2022-06-07T17:28:00+08:00

weight: 100

---

“统计学习”在自然科学、金融和实业界中的很多领域都发挥了重要的作用，以下为一些具体应用场景：

- 根据人口统计学特征、饮食和临床指标，预测一个由于心脏病入院治疗的病人是否会再次突发心脏病。
- 基于某家公司的基本面表现数据以及宏观经济数据，预测六个月之后该公司的股票价格。
- 从扫描数字化的图片中，识别出手写的邮政编码数字。
- 利用一个糖尿病患者血液样本的红外吸收光谱，估计出这个人的血糖浓度。
- 基于临床指标和人口统计学特征，识别（不同个体的）患前列腺癌症的风险程度。

在统计学、数据挖掘、人工智能，以及与工程和其他学科的交叉领域中，对“统计学习”的研究也很重要。

简单来说，本书介绍如何“学习”数据中的信息。在一个典型的场景中，我们通常有一个量化的（比如股票价格）或类别的（比如“是否突发心脏病”）目标指标，我们希望可以利用一组特征（比如饮食和临床指标）来预测目标指标。我们有一组训练集数据，从中我们可以研究一组样本（比如一群人）的目标指标与特征值。利用这组数据，我们建立一个预测模型（学习模型），我们可以使用这个模型对不在这组数据中的新样本的目标指标。一个好的学习模型应可以准确地预测目标值表。

上述场景即为所谓的“监督学习”问题。称之为“监督”，是因为训练集包含了已知的目标指标来指导模型的学习过程。在“无监督学习”问题中，我们只能观测到一组样本的特征，而没有目标指标。这时的问题变为描述数据内部是如何关联和分类的。本书的大部分内容是关于有监督学习的，[第十四章]({{< relref "../ch14/_index.md" >}})会集中介绍无监督学习，其研究领域相对还不成熟。

以下是几个真实的统计学习问题例子。

### 例一：垃圾邮件

这个例子所用的数据为包括 4601 封电子邮件，来自于一项预测电子邮件是否为垃圾邮件的研究。目标是设计一个骚扰邮件的自动探测器，可以将其从用户的邮箱中过滤掉。每封电子邮件样本都包含目标变量（邮件类型，即是正常邮件还是垃圾邮件）和邮件中 57 个最常出现的单词和标点符号的相对频率。这是一个监督学习问题，目标变量为二分类的变量（正常邮件/垃圾邮件）。这种也被称为分类问题。

表 1.1 列出了正常邮件和垃圾邮件中的平均出现相对频率差别最大的词。

|     | george | you | your | hp  | free | hpl | !   | our | re  | edu | remove |
| --- | ------ | --- | ---- | --- | ---- | --- | --- | --- | --- | --- | ------ |
| spam       | 0.00 | 2.26 | 1.38 | 0.02 | 0.52 | 0.01 | 0.51 | 0.51 | 0.13 | 0.01 | 0.28 |
| email      | 1.27 | 1.27 | 0.44 | 0.90 | 0.07 | 0.43 | 0.11 | 0.18 | 0.42 | 0.29 | 0.01 |
| abs(diff)[^1]  | 1.27 | 0.99 | 0.94 | 0.88 | 0.45 | 0.42 | 0.40 | 0.33 | 0.29 | 0.28 | 0.27 |

**表 1.1**：单词或符号在整篇邮件所占的百分比的平均值。这里展示了在骚扰邮件和正常邮件中差异最大的单词或符号。

我们的学习器要决定利用哪些特征和如何用这些特征。例如，我们可以制定这样的规则：

```
如果 ( %george < 0.6) 并且 ( %you > 1.5) 那么 spam
                                        其他 email.
```
或者这样的规则：
```
如果 (0.2 * %you − 0.3 * %george ) > 0  那么 spam
                                        其他 email.
```

在此场景中，不同的分类错误会有不同程度的影响：应尽量避免过滤掉正常邮件，放过一些垃圾邮件反而是可以接受的。有很多种解决这个问题的方法，会在相应章节介绍。

### 例二：前列腺癌症

[图 1.1](#figure-f0101) 展示的数据，来自于 Stamey et al. (1989) 的一项关于前列腺特异抗原（PSA）水平与一些临床指标之间的相关性的研究，样本为 97 名即将彻底切除前列腺的男性病人。

{{< figure
  src="https://public.guansong.wang/eslii/ch01/eslii_fig_01_01.png"
  id="f0101"
  title="**图 1.1**：前列腺癌症数据集的变量两两散点图矩阵。第一行显示了各个预测变量与目标变量的散点分布。预测变量 svi 和 gleason 为分类变量。"
>}}

研究的目的是基于一些临床指标来预测取对数后的 PSA 水平（lpsa），这些指标包括癌肿瘤体积的对数（lcavol），前列腺重量的对数（lweight），年龄（age），良性前列腺增生数量的对数（lbph），是否存在精囊侵袭（svi），囊穿透的对数（lcp），格里森评分（gleason），以及格里森评分 4 和 5 所占百分比（pgg45）。[图 1.1](#figure-f0101) 为这些变量的两两散点图矩阵。明显有些变量与目标变量 lpsa 存在相关性，但仅凭肉眼很难建立起一个有效的模型。

这是一个监督学习问题，也是一个回归问题，因为其目标变量为量化的指标。

### 例三：手写数字识别

这个例子中的数据为美国邮政信件信封上手写的邮政编码数字。从邮政编码五位数字中分割出了每个数字的图片。这些图片为 16*16 的 8-bit 灰度图，每个像素的灰度深浅取值范围从 0 到 255。[图 1.2](#figure-f0102) 展示了一些样本图片。

{{< figure
  src="https://public.guansong.wang/eslii/ch01/eslii_fig_01_02.png"
  id="f0102"
  title="**图 1.2**：美国邮政信件信封上手写数字的样例。"
>}}

图片会经过规范化处理，使其大小和方向差不多一致。目标是利用这些 16*16 的像素灰度深浅矩阵快速并准确地识别出途中的数字（0，1，……，9）。如果准确率够高，则可以利用这个算法实现自动化信件分拣过程。这是一个分类问题，而且为了避免错发信件，要求模型的错误率要足够低。为了达到低错误率，可以将一些信件标记为“不确定”而手动分拣。

### 例四：DNA表达序列

DNA 全称为脱氧核糖核酸，是组成人类染色体的基本物质。DNA 微阵列（microarray）通过测量体现某个基因的 mRNA（信使核糖核酸）的数量来测量一个细胞中该基因的表达。微阵列被视为生物学领域的突破性技术，可以从单个细胞样本对上千个基因同时进行量化研究。

DNA 微阵列的工作原理如下。[^2]
将上千个基因的核苷酸序列印在一个玻璃片上。使用红色和绿色染剂标记一个目标样本和一个参考样本，将它们分别与玻璃片上的 DNA 杂交。测量通过荧光透视后的每个点的 RNA 杂交（红/绿）强度的对数。得到的结果是数千个数字，通常取值在 -6 到 6 之间，代表着每个目标基因相对于参考样本的表达水平。正值标志着目标样本的表达水平高于参考样本，负值反之。

基因表达数据集汇集一组 DNA 微阵列检测的表达水平数值结果，其中每一列代表着一次检测结果。因此通常会有数千行代表着不同的基因，数十列代表不同的检测样本结果。在这个例子中有 6830 个基因（行）以及 64 个样本（列），图 1.3 只随机地展示了其中的 100 行。[图 1.3](#figure-f0103) 以热力图显示这个数据集，颜色范围为从绿色（负值）到红色（正值）。样本的来源为 64 个不同患者的癌症肿瘤。

{{< figure
  src="https://public.guansong.wang/eslii/ch01/eslii_fig_01_03.png"
  id="f0103"
  title="**图 1.3**：DNA 微阵列数据，人类肿瘤的 6830 个基因（行）和 64 个样本（列）的表达矩阵。这里只随机展示了其中的 100 行。热力图的颜色从绿色（负值，欠表达）到红色（正值，过表达）。缺失值以灰色标记。行与列的顺序为随机选取，无特殊含义。"
>}}

这里面临的问题是理解基因的表达与样本之间的关系。以下为几个典型的问题：

- 哪几个样本在基因的表达水平上彼此最相似？
- 哪些基因在不同样本中的表达水平类似？
- 是否有某些基因在特定的癌症样本中有非常高（或非常低）的表达水平？

这个场景可以被看成一个回归问题，两个类别的预测变量（基因和癌症类型），目标变量为表达水平。然而无监督学习可能更适合这个问题。例如典型问题中的第一个，样本可以被视为在 6830 维度空间上的点，我们可以在上面尝试某种分类算法。

### 针对读者

本书所面向的读者为统计学、人工智能、工程、金融等领域的学生和研究人员。我们默认读者至少修过一门入门统计学课程，理解包括线性回归等基础内容。

我们的目的不是完成一部关于统计学习包罗万象的全书，而只是介绍其中最重要的内容。同时，我们更想介绍的是基础的概念和逻辑框架，使研究者可以应用于任意的统计学习方法中。相比具体的数学技巧，本书更强调的是概念的理解。

本书的作者均为统计学家，对一些问题的理解和阐述也自然地体现了统计学的视角。但作者也不断参加神经网络、数据挖掘和机器学习的学术会议，思考方式一直被这些领域所影响。这在作者的研究和本书也有所体现。

### 章节安排

我们的观点是应先理解了简单的内容后再尝试复杂的内容。因此，在[第二章]({{< relref "../ch02/_index.md" >}})概述有监督学习问题后，[第三章]({{< relref "../ch03/_index.md" >}})和[第四章]({{< relref "../ch04/_index.md" >}})讨论回归和分类的线性模型。[第五章]({{< relref "../ch05/_index.md" >}})讲述单个模型的样条、小波、正则化/惩罚项方法，[第六章]({{< relref "../ch06/_index.md" >}})涵盖核方法和局部回归，这两个章节都是高维的学习算法的重要基础。[第七章]({{< relref "../ch07/_index.md" >}})为模型评估与选择，包含偏差、方差、过拟合等概念，以及模型选择的方法，比如交叉验证。[第八章]({{< relref "../ch08/_index.md" >}})讨论模型的推断和平均，包括最大似然方法、贝叶斯推断与自助法、EM （期望最大化）算法、吉布斯采样、和 bagging 方法。与此相关的 boosting 方法集中在[第十章]({{< relref "../ch10/_index.md" >}})。

第九至十三章为一些结构化的监督学习方法，[第九章]({{< relref "../ch09/_index.md" >}})和[第十一章]({{< relref "../ch11/_index.md" >}})覆盖了回归问题，[第十二章]({{< relref "../ch12/_index.md" >}})和[第十三章]({{< relref "../ch13/_index.md" >}})覆盖了分类问题。[第十四章]({{< relref "../ch14/_index.md" >}})介绍了无监督学习。[第十五章]({{< relref "../ch15/_index.md" >}})和[十六章]({{< relref "../ch16/_index.md" >}})讨论了两个比较新的方法，随机森林和集成学习。[第十七章]({{< relref "../ch17/_index.md" >}})介绍无向图模型，最终在[第十八章]({{< relref "../ch18/_index.md" >}})介绍高维度的问题。

每章的结尾会讨论在实际应用中的计算复杂度，包括随样本和维度变大后复杂度的增加程度。参考资料和文献目录附在章节后。

我们推荐先依次阅读第 1-4 章。此外，第 7 章讨论了有关统计学习的一般性的重要概念，所以应为必读。本书的其他章节，则可以根据读者的兴趣，按顺序或选择性阅读。

这个表情 :scream: 用于标记比较复杂的段落，跳过这些内容不会影响主要部分的阅读。

### 网站

本书的配套网站地址为：http://www-stat.stanford.edu/ElemStatLearn

其中有很多资源，包括很多本书中使用的数据集。

### 教学提示

本书第一版比较适合作为两学期课程的教材。第二版添加了内容后，可以将本书分为三个学期。每张的结尾提供了练习题。软件工具的使用对学习本书内容十分重要。在我们的课程中使用了 R/S-PLUS 语言。


[^1]: 最后一列为前两列（spam 与 email）之间差的绝对值。
[^2]: 基本看不懂这个例子，仅作参考。