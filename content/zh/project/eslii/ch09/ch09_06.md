---
title: 9.6 缺失数据
summary: >
  第 332-333 页。如果缺失值不多，可舍弃存在缺失值的样本。一些模型，如树结构模型（CART、MARS 和 PRIM）以及广义加性模型，在拟合过程中可以适应存在缺失值的训练集。另外，一般的方法是用某种模型的预测来填充缺失的特征变量。

date: 2019-01-16T15:06:00+08:00

weight: 906

---

数据中存在缺失一个或多个输入变量特征的样本是非常普遍发生的情况。通常的解决方法是用某种方式填补（impute）缺失值。

不过在处理缺失值问题时首先要确定数据缺失的机制是否会扭曲观测数据样本的分布。简单来说，如果造成样本中变量取值缺失的机制与其取值大小无关，那么数据是随机地缺失的。Little and Rubin (2002) 中对这进行了更严谨的定义。假设 $\mathbf{y}$ 为输出变量向量，$\mathbf{X}$ 为 $N\times p$ 的输入变量矩阵（其中有一些缺失值）。记 $\mathbf{X}\_\text{obs}$ 为 $\mathbf{X}$ 有观测值的元素，并且令 $\mathbf{Z}=(\mathbf{y},\mathbf{X})$ 以及 $\mathbf{Z}\_\text{obs}=(\mathbf{y},\mathbf{X}\_\text{obs})$。最后，令 $\mathbf{R}$ 为一个指示矩阵，如果 $x_{ij}$ 缺失则其第 ij 个元素为 1，否则为 0。如果 $\mathbf{R}$ 的分布对数据 $\mathbf{Z}$的依赖只体现在 $\mathbf{Z}\_\text{obs}$ 中，则称数据是**随机缺失**（missing at random，MAR）的：

{{< math >}}
$$\operatorname{Pr}(\mathbf{R} | \mathbf{Z}, \theta) =
  \operatorname{Pr}(\mathbf{R} | \mathbf{Z}_\text{obs}, \theta) \tag{9.31}$$
{{< /math >}}

其中 $\theta$ 为 $\mathbf{R}$ 的分布中的参数。如果 $\mathbf{R}$ 的分布不依赖于观测到或缺失的数据，则称数据是 **完全随机缺失（missing completely at random，MCAR）** 的：

{{< math >}}
$$\operatorname{Pr}(\mathbf{R} | \mathbf{Z}, \theta) =
  \operatorname{Pr}(\mathbf{R} | \theta) \tag{9.32}$$
{{< /math >}}

MCAR 的假设比 MAR 的假设更强，大多数填补方法的有效性基于 MCAR。

例如，如果因为医生觉得一个患者的病症很明显而没有查验其相应的测量指标，那么观测样本就既不是随机缺失也不是完全随机缺失。在这样的场景中，缺失数据的机制导致了观测到的训练集是真实总体样本的一个扭曲的抽样，并且在这里进行数据填充是危险的。通常需要从数据采集过程的相关信息中判断输入特征是否满足完全随机缺失。对类别特征变量，可以将“缺失”编码为一个额外的类别，来判断是否随机缺失。在训练集上拟合模型后考察这个“缺失”的类别是否对输出变量有解释性。

假设特征变量是完全随机缺失的，那么有以下几个处理方法：

1. 舍弃所有存在缺失值的观测样本。
2. 依赖学习算法在训练模型时对缺失值的处理机制。
3. 在训练前填补所有的缺失值。

如果缺失数据的相对数量较小，可以使用方法（1），否则应该避免舍弃样本。对于方法（2），CART 通过 **替代分割（surrogate splits）** 的方法（[第 9.2.4 节]({{< relref "../ch09/ch09_02.md#924-其他问题" >}})）可以有效地处理缺失值。MARS 和 PRIM 也采用了与之类似的方法。广义加性模型在回修算法中基于某个特征变量对部分残差平滑时，会忽略所有缺失这个特征的观测样本。由于（当模型中包括了截距项时）拟合曲线的均值为零，这相当于用拟合值的平均填充了存在缺失值的样本。

对于大多数的学习方法，则需要使用填充的方法（3）。最简单的策略是用一个特征变量的非缺失数据的均值或中位数来填充这个变量的缺失值。（注意这与上述广义加性模型的处理方式相似。）

如果特征之间存在某些适度的相关性，那么一个更好的方法是为每个特征变量建立基于其他特征变量的预测模型，然后用模型的预测来填充特征的缺失值。需要指出填充特征变量选择的学习方法与从 $\mathbf{X}$ 预测 $\mathbf{y}$ 的学习方法是不同的。因此通常倾向于选择一个灵活、自适应的方法，即使最终的模型只是一个 $\mathbf{y}$ 对 $\mathbf{X}$ 的线性回归。另外，如果训练集中有非常多的缺失值特征变量，那么填充特征的学习方法本身需要有处理缺失值的能力。因此 CART 是作为填充“引擎”的一个理想的选择。

在填充了缺失值后，通常将其视为其他观测值一样处理。这忽略了由填充而引入的不确定性，它本身也会对输出变量模型的估计和预测中引入额外的不确定性。可以通过多次的填充来测量这个额外的不确定性，也因此会得到多个不同的训练集。可以在每个训练集上拟合 $\mathbf{y}$ 的预测模型，然后评估不同训练集上结果的变动。如果使用了 CART 作为填充引擎，那么可以在对应终节点中的样本取值中进行抽样来实现多次的填充。