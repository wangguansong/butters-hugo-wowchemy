---
title: 8.8 模型平均和堆叠（stacking）
summary: >
  第 288-290 页。在对模型的平均中，委员会方法赋予各个模型相同的权重，堆叠方法赋予各个模型（估计）最优权重。

date: 2018-12-27T11:27:00+08:00
lastmod: 2018-12-27T11:27:00+08:00
linktitle: 8.8 模型平均和堆叠

weight: 808

---

[第 8.4 节]({{< relref "ch08_04.md" >}})从非参数贝叶斯分析的角度，将一个估计的自助抽样视为对应参数的近似后验分布抽样。从这个角度理解，自助聚合估计（表达式 8.51）是近似的后验贝叶斯均值。相比之下，训练样本估计 $\hat{f}(x)$ 对应着后验分布的众数。由于后验均值（而不是众数）最小化平方误差损失，所以通常自助聚合会降低均方误差。

本节讨论更广义的贝叶斯模型平均。在训练集 $\mathbf{Z}$ 上有一组候选模型 $\mathcal{M}\_m$，$m=1,\dots,M$。这些模型可能是不同参数的同种模型（例如选取特征子集的线性回归），或同一个问题的不同模型（例如神经网络和回归树）。

假设 $\zeta$ 为某个感兴趣的数值，例如在某个固定特征取值 $x$ 处的预测 $f(x)$。$\zeta$ 的后验分布为：

$$\operatorname{Pr}(\zeta|\mathbf{Z}) = \sum_{m=1}^M
\operatorname{Pr}(\zeta|\mathcal{M}\_m,\mathbf{Z})
\operatorname{Pr}(\mathcal{M}\_m|\mathbf{Z}) \tag{8.53}$$

后验均值为：

$$\operatorname{E}[\zeta|\mathbf{Z}] = \sum_{m=1}^M
\operatorname{E}(\zeta|\mathcal{M}\_m, \mathbf{Z})
\operatorname{Pr}(\mathcal{M}\_m|\mathbf{Z}) \tag{8.54}$$

这个贝叶斯预测是各个预测的加权平均，权重与每个模型的后验概率成比例。

从这个表达式可引出几个不同的模型平均的策略。**委员会（committee）**方法对每个模型的预测进行简单的不加权平均，本质上是给每个模型赋予相同的概率。更进一步，[第 7.7 节]({{< relref "../ch07/ch07_07.md" >}})中说明了 BIC 准则可被用于估计后验模型概率。这适用于由同参数模型产生但参数取值不同的模型的场景中。BIC 根据模型的拟合程度和使用的参数个数来给每个模型赋予权重。现也可以进行完整的贝叶斯方法。若每个模型 $\mathcal{M}\_m$ 的参数为 $\theta_m$，则有：

$$\begin{align}
& \operatorname{Pr}(\mathcal{M}\_m|\mathbf{Z}) \propto 
  \operatorname{Pr}(\mathcal{M}\_m) \cdot
  \operatorname{Pr}(\mathbf{Z} | \mathcal{M}\_m) \\\\
& \propto
  \operatorname{Pr}(\mathcal{M}\_m) \cdot
  \int \operatorname{Pr}(\mathbf{Z} | \theta_m, \mathcal{M}\_m)
  \operatorname{Pr}(\theta_m | \mathcal{M}\_m) d\theta_m
\tag{8.55}\end{align}$$

原则上，可以指定先验概率 $\operatorname{Pr}(\theta_m|\mathcal{M}\_m)$ 并通过表达式 8.55 用数值计算作为模型平均权重的后验概率。然而，我们并没有见到实际的证据表明这个方法相较于更简单的 BIC 近似有明显的提高。

那么如何从频率学派（frequentist）的角度理解模型平均？给定预测值 $\hat{f}\_1(x)$，$\hat{f}\_2(x)$，……，$\hat{f}\_M(x)$，对平方误差损失需要寻找权重 $w=(w_1,w_2,\dots,w_M)$，使得：

$$\hat{w} = \underset{w}{\arg\min} \operatorname{E}\_\mathcal{P} \left[
Y - \sum_{m=1}^M w_m \hat{f}\_m(x)
\right]^2 \tag{8.56}$$

其中将输入变量 $x$ 视为常数，数据集 $\mathbf{Z}$ 中的 N 个观测值（以及目标变量 $Y$）服从 $\mathcal{P}$ 分布。其解为样本总体上 $Y$ 对 $\hat{F}(x)\equiv[\hat{f}\_1(x),\hat{f}\_2(x),\dots,\hat{f}\_M(x)]$ 的线性回归：

$$\hat{w} = \operatorname{E}\_\mathcal{P}[\hat{F}(x)\hat{F}(x)^T]^{-1}
\operatorname{E}\_\mathcal{P}[\hat{F}(x)Y] \tag{8.57}$$

现在完整的回归比任意单独的模型有更小的平方误差：

$$\operatorname{E}\_\mathcal{P}
\left[Y - \sum_{m=1}^M \hat{w}\_m \hat{f}\_m(x)\right]^2 \leq 
\operatorname{E}\_\mathcal{P} \left[Y - \hat{f}\_m(x)\right]^2 \forall m \tag{8.58}$$

所以从样本总体分布上看，模型的组合总会对结果有所帮助。

当然，样本总体线性回归（表达式 8.57）并不可得，自然地可以用训练集上的线性回归作为替代。但可用一些简单的例子说明这效果并不好。例如，假设 $\hat{f}\_m(x)$，$m=1,2,\dots,M$ 代表了 $M$ 个输入变量中的 $m$ 大小的最优输入变量子集所产生的预测，那么线性回归会将全部权重赋予最大的模型，即 $\hat{w}\_M=1$，$\hat{w}\_m=0$，$m<M$。问题在于并没有考虑到它们的模型复杂度（这个例子中是输入变量的个数 $m$），从而对每个模型进行公平地比较。

**堆叠泛化（stacked generalization）** 或 **堆叠（stacking）** 即是一个如此的方法。另 $\hat{f}\_m^{-i}(x)$ 为模型 $m$ 应用在排除第 i 个训练观测值的训练集上，在 $x$ 点处的预测值。从 $y_i$ 对 $\hat{f}\_m^{-i}(x_i)$，$m=1,2,\dots,M$ 的最小二乘线性回归可得出权重的堆叠估计。具体地，可将堆叠权重写为：

$$\hat{w}^\text{st} = \underset{w}{\arg\min} \sum_{i=1}^N \left[
y_i - \sum_{m=1}^M w_m \hat{f}^{-i}\_m(x_i) \right]^2
\tag{8.59}$$

最终的预测值为 $\sum_m\hat{w}\_m^\text{st}\hat{f}\_m(x)$。通过使用交叉验证类型的预测 $\hat{f}\_m^{-i}(x)$，堆叠避免了给高复杂度的模型赋予不公平的高权重。对权重加上非负并且和为一的约束后，可得到更好的结果。若将权重理解为表达式 8.54 中的后验模型概率，那么这种约束看起来比较合理，而且会得到一个易于处理的二次规划问题。

堆叠和通过留一法（leave-one-out）交叉验证（[第 7.10 节]({{< relref "../ch07/ch07_10.md" >}})）之间存在紧密的联系。如果给表达式 8.59 中最小化约束在只有一个位置为一其他位置为零的权重向量 $w$ 上，那么得出的是留一法交叉验证误差最小的模型选择 $\hat{m}$。堆叠没有选择一个单一的模型，而是用估计的最优权重结合模型。这通常会得出更好的预测，但会比从 $M$ 个模型中选择其中一个的解释性差一些。

堆叠的思想实际上要比上述的更广泛。可以使用任意的学习方法，而不只是线性回归，计算表达式 8.59 中的权重来结合模型；这个权重也可以依赖于输入变量 $x$ 的取值。这样看，是通过将学习方法“堆叠”在彼此之上来改进预测的效果。