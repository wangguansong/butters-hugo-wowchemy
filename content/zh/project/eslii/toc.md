---
title: "统计学习基础：目录索引"
summary: "“统计学习基础”（ESL）一书的章节目录索引，随完成进度更新。"

date: 2018-08-27T15:18:10+08:00
lastmod: 2019-02-28T16:20:00+08:00

weight: 10
linktitle: 目录索引

---


另外可参考 Wei Ya 的翻译版本（[链接](https://esl.hohoweiya.xyz/)）。

1.  [序言]({{< relref "ch01/_index.md" >}})
2.  [监督学习概述]({{< relref "ch02/_index.md" >}})
    1.  [引言]({{< relref "ch02/_index.md" >}})
    2.  [变量类型和术语]({{< relref "ch02/ch02_02.md" >}})
    3.  [两个简单的预测方法：最小二乘和最近邻域]({{< relref "ch02/ch02_03.md" >}})
    4.  [统计决策理论]({{< relref "ch02/ch02_04.md" >}})
    5.  [局部方法中的高维度问题]({{< relref "ch02/ch02_05.md" >}})
    6.  [统计模型、监督学习和函数逼近]({{< relref "ch02/ch02_06.md" >}})
    7.  [有结构的回归模型]({{< relref "ch02/ch02_07.md" >}})
    8.  [有约束的估计模型类型]({{< relref "ch02/ch02_08.md" >}})
    9.  [模型选择和偏差方差权衡]({{< relref "ch02/ch02_09.md" >}})
3.  [回归问题的线性方法]({{< relref "ch03/_index.md" >}})
    1.  [引言]({{< relref "ch03/_index.md" >}})
    2.  [线性回归模型和最小二乘]({{< relref "ch03/ch03_02.md" >}})
    3.  [变量子集选择]({{< relref "ch03/ch03_03.md" >}})
    4.  [收缩方法]({{< relref "ch03/ch03_04.md" >}})
    5.  [衍生输入变量的方法]({{< relref "ch03/ch03_05.md" >}})
    6.  [讨论：子集选择和收缩方法的比较]({{< relref "ch03/ch03_06.md" >}})
    7.  [多输出变量的收缩和变量选择 :scream:]({{< relref "ch03/ch03_07.md" >}})
    8.  [更多关于套索回归和类似的路径算法]({{< relref "ch03/ch03_08.md" >}})
    9.  [计算量考量]({{< relref "ch03/ch03_09.md" >}})
4.  [分类问题的线性方法]({{< relref "ch04/_index.md" >}})
    1.  [引言]({{< relref "ch04/_index.md" >}})
    2.  [对指示变量矩阵的线性回归]({{< relref "ch04/ch04_02.md" >}})
    3.  [线性判别分析]({{< relref "ch04/ch04_03.md" >}})
    4.  [对数几率回归（逻辑回归）]({{< relref "ch04/ch04_04.md" >}})
    5.  [分离超平面]({{< relref "ch04/ch04_05.md" >}})
5.  [基拓展和正则化]({{< relref "ch05/_index.md" >}})
    1.  [引言]({{< relref "ch05/_index.md" >}})
    2.  [分段多项式和样条]({{< relref "ch05/ch05_02.md" >}})
    3.  [滤波和特征提取]({{< relref "ch05/ch05_03.md" >}})
    4.  [平滑样条]({{< relref "ch05/ch05_04.md" >}})
    5.  [平滑参数的自动选择]({{< relref "ch05/ch05_05.md" >}})
    6.  [非参数对数几率回归]({{< relref "ch05/ch05_06.md" >}})
    7.  [多维样条]({{< relref "ch05/ch05_07.md" >}})
    8.  [正则化与再生核希尔伯特空间 :scream:]({{< relref "ch05/ch05_08.md" >}})
    9.  [小波平滑]({{< relref "ch05/ch05_09.md" >}})
    10. Appendix: Computations for Splines
6.  [核平滑方法]({{< relref "ch06/_index.md" >}})
    1.  [一维的核平滑器]({{< relref "ch06/ch06_01.md" >}})
    2.  [核函数窗宽的选择]({{< relref "ch06/ch06_02.md" >}})
    3.  [$\mathbb{R}^p$ 上的局部回归]({{< relref "ch06/ch06_03.md" >}})
    4.  [ℝᵖ 上的结构化局部线性回归模型]({{< relref "ch06/ch06_04.md" >}})
    5.  [局部似然和其他模型]({{< relref "ch06/ch06_05.md" >}})
    6.  [核密度估计与分类问题]({{< relref "ch06/ch06_06.md" >}})
    7.  [径向基函数与核函数]({{< relref "ch06/ch06_07.md" >}})
    8.  [密度估计的混合模型与分类问题]({{< relref "ch06/ch06_08.md" >}})
    9.  [计算量考量]({{< relref "ch06/ch06_09.md" >}})
7.  [模型评估和选择]({{< relref "ch07/_index.md" >}})
    1.  [引言]({{< relref "ch07/_index.md" >}})
    2.  [偏差、方差和模型复杂度]({{< relref "ch07/ch07_02.md" >}})
    3.  [偏差-方差分解]({{< relref "ch07/ch07_03.md" >}})
    4.  [训练误差率中的乐观值]({{< relref "ch07/ch07_04.md" >}})
    5.  [样本内预测误差的估计]({{< relref "ch07/ch07_05.md" >}})
    6.  [有效参数个数]({{< relref "ch07/ch07_06.md" >}})
    7.  [贝叶斯方法和 BIC]({{< relref "ch07/ch07_07.md" >}})
    8.  [最小描述长度]({{< relref "ch07/ch07_08.md" >}})
    9.  [万普尼克-泽范兰杰斯维度 :scream:]({{< relref "ch07/ch07_09.md" >}})
    10. [交叉验证]({{< relref "ch07/ch07_10.md" >}})
    11. [自助法]({{< relref "ch07/ch07_11.md" >}})
    12. [条件还是无条件期望测试误差？]({{< relref "ch07/ch07_12.md" >}})
8.  [模型的推断和平均]({{< relref "ch08/_index.md" >}})
    1.  [引言]({{< relref "ch08/_index.md" >}})
    2.  [自助法和最大似然方法]({{< relref "ch08/ch08_02.md" >}})
    3.  [贝叶斯方法]({{< relref "ch08/ch08_03.md" >}})
    4.  [自助法与贝叶斯推断的关系 :scream:]({{< relref "ch08/ch08_04.md" >}})
    5.  [最大期望（EM）算法]({{< relref "ch08/ch08_05.md" >}})
    6.  [后验分布的马尔可夫链蒙特卡洛抽样]({{< relref "ch08/ch08_06.md" >}})
    7.  [自助聚合（Bagging）]({{< relref "ch08/ch08_07.md" >}})
    8.  [模型平均和堆叠（stacking）]({{< relref "ch08/ch08_08.md" >}})
    9.  [随机搜索：Bumping]({{< relref "ch08/ch08_09.md" >}})
9.  [加性模型、树模型和相关方法]({{< relref "ch09/_index.md" >}})
    1.  [广义加性模型]({{< relref "ch09/_index.md" >}})
    2.  [树结构模型]({{< relref "ch09/ch09_02.md" >}})
    3.  [PRIM（耐心规则归纳方法）：凸块搜索]({{< relref "ch09/ch09_03.md" >}})
    4.  [多元自适应回归样条（MARS）]({{< relref "ch09/ch09_04.md" >}})
    5.  [层级混合专家]({{< relref "ch09/ch09_05.md" >}})
    6.  [缺失数据]({{< relref "ch09/ch09_06.md" >}})
    7.  [计算量考量]({{< relref "ch09/ch09_07.md" >}})
10. [提升方法和加性树模型]({{< relref "ch10/_index.md" >}})
    1.  [提升方法]({{< relref "ch10/_index.md" >}})
    2.  [提升方法是一个加性模型的拟合]({{< relref "ch10/ch10_02.md" >}})
    3.  [前向分段加性模型]({{< relref "ch10/ch10_03.md" >}})
    4.  [指数损失函数与自适应提升]({{< relref "ch10/ch10_04.md" >}})
    5.  [为何用指数损失函数？]({{< relref "ch10/ch10_05.md" >}})
    6.  [损失函数和稳健性]({{< relref "ch10/ch10_06.md" >}})
    7.  [数据挖掘中“现成”的方法]({{< relref "ch10/ch10_07.md" >}})
    8.  [示例：垃圾邮件数据]({{< relref "ch10/ch10_08.md" >}})
    9.  [提升树模型]({{< relref "ch10/ch10_09.md" >}})
    10. [通过梯度提升进行数值最优化]({{< relref "ch10/ch10_10.md" >}})
    11. [提升方法中树模型的合理大小]({{< relref "ch10/ch10_11.md" >}})
    12. [正则化]({{< relref "ch10/ch10_12.md" >}})
    13. [模型解释]({{< relref "ch10/ch10_13.md" >}})
    14. [示例]({{< relref "ch10/ch10_14.md" >}})
11. [神经网络]({{< relref "ch11/_index.md" >}})
    1.  [引言]({{< relref "ch11/_index.md" >}})
    2.  [投影寻踪回归]({{< relref "ch11/ch11_02.md" >}})
    3.  [神经网络]({{< relref "ch11/ch11_03.md" >}})
    4.  [神经网络的拟合]({{< relref "ch11/ch11_04.md" >}})
    5.  [训练神经网络的一些问题]({{< relref "ch11/ch11_05.md" >}})
    6.  [示例：模拟数据]({{< relref "ch11/ch11_06.md" >}})
    7.  [示例：邮政编码数据]({{< relref "ch11/ch11_07.md" >}})
    8.  [讨论]({{< relref "ch11/ch11_08.md" >}})
    9.  [贝叶斯神经网络和 NIPS 2003 挑战赛]({{< relref "ch11/ch11_09.md" >}})
    10. [计算量考量]({{< relref "ch11/ch11_10.md" >}})
12. 支持向量机和灵活判别
    1.  [引言]
    2.  [The Support Vector Classifier]
    3.  [Support Vector Machines and Kernels]
    4.  [Generalizing Linear Discriminant Analysis]
    5.  [Flexible Discriminant Analysis]
    6.  [Penalized Discriminant Analysis]
    7.  [Mixture Discriminant Analysis]
13. Prototype Methods and Nearest-Neighbors
    1.  [引言]
    2.  [Prototype Methods]
    3.  [k-Nearest-Neighbor Classifiers]
    4.  [Adaptive Nearest-Neighbor Methods]
    5.  [Computational Considerations]
14. Unsupervised Learning
    1.  [引言]
    2.  [Association Rules]
    3.  [Cluster Analysis]
    4.  [Self-Organizing Maps]
    5.  [Principal Components, Curves and Surfaces]
    6.  [Non-negative Matrix Factorization]
    7.  [Independent Component Analysis]
    8.  [Multidimensional Scaling]
    9.  [Nonlinear Dimension Reduction and Local Multidimensional Scaling]
    10. [The Google PageRank Algorithm]
15. Random Forests
    1.  [引言]
    2.  [Definition of Random Forests]
    3.  [Details of Random Forests]
    4.  [Analysis of Random Forests]
16. Ensemble Learning
    1.  [引言]
    2.  [Boosting and Regularization Paths]
    3.  [Learning Ensembles]
17. Undirected Graphical Models
    1.  [引言]
    2.  [Markov Graphs and Their Properties]
    3.  [Undirected Graphical Models for Continuous Variables]
    4.  [Undirected Graphical Models for Discrete Variables]
18. High-Dimensional Problems: $p \gg N$
    1.  [When $p$ is Much Bigger than $N$]
    2.  [Diagonal Linear Discriminant Analysis and Nearest Shrunken Centroids]
    3.  [Linear Classifiers with Quadratic Regularization]
    4.  [Linear Classifiers with $\text{L}\_1$ Regularization]
    5.  [Classification When Features are Unavailable]
    6.  [High-Dimensional Regression: Supervised Principal Components]
    7.  [Feature Assessment and the Multiple-Testing Problem]
