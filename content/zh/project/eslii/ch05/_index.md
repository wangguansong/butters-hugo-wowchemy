---
title: 5 基拓展和正则化
summary: >
  第 139-190 页。第五章为基拓展及其正则化方法，进入非线性方法的范畴。

date: 2018-10-17T09:39:00+08:00
lastmod: 2022-06-14T11:08:00+08:00

weight: 501

---

之前的章节介绍了用于回归和分类问题的对输入特征变量呈线性的模型。诸如线性回归、线性判别分析、对数几率回归、和分离超平面等模型都建立在线性的关系上。然而真实的关系函数 $f(X)$ 非常不可能是 $X$ 的线性函数。在回归问题中，$f(X) = E(Y|X)$ 通常对 $X$ 为非线性并且没有加性[^1]，对 $f(X)$ 的线性假设常常是一个方便的近似，有时可能是必要的简化。由于线性函数易于理解，并可视为是 $f(X)$ 的一阶泰勒近似，所以“方便”；在 $N$ 比较小而且 $p$ 比较大时，有可能线性模型是唯一可避免过拟合的方法，所以“有时必要”。在分类问题中也类似，线性的贝叶斯最优判别边界假定 $\operatorname{Pr}(Y=1|X)$ 的某种单调转化为 $X$ 的线性函数。这也是对真实概率的一个近似。

本章和下一章会介绍摆脱线性假设的常用方法。本章的基本想法是在输入变量中添加从 $X$ 上转化生成的新变量，在新的衍生输入特征变量的空间上使用线性模型。

假设 $h_m(X): \mathbb{R}^p \mapsto \mathbb{R}$ 为 $X$ 的第 m 个转化变量，$m = 1, \dots, M$。则模型可表述为：

$$f(X) = \sum_{m=1}^M \beta_m h_m(X) \tag{5.1}$$

其为 $X$ 的 **线性基拓展（linear basis expansion）**。这个方法的优点在于确定了 $h_m$ 后，模型对拓展后的输入变量为线性，可以用之前介绍的方法拟合。

以下为几个简单并使用广泛的 $h_m$ 例子：

* $h_m(X) = X_m, m = 1, \dots, p$ 则等同于线性模型。
* $h_m(X) = X_j^2$ 或 $h_m(X) = X_j X_k$ 允许在输入变量中添加多项式项从而在近似中达到更高阶的泰勒拓展项。但需要注意的是变量个数会随着多项式的级数以指数级增长。一个 $p$ 个变量生成的完整二次多项式模型需要 $O(p^2)$ 个平方和交叉项；一个 $d$ 阶层多项式需要生成 $O(p^d)$ 个输入变量。
* $h_m(X) = \log(X_j), \sqrt{X_j}, \dots$ 纳入对单输入变量的其他一些非线性转换。也可使用其他涉及多个输入变量的简单函数，比如 $h_m(X) = \\|X\\|$。
* $X_k$ 在某个区间上的指示函数：$h_m(X) = I(L_m \leq X_k < U_m)$。将 $X_k$ 取值划分 $M_k$ 个不重叠的区间，使其对模型结果的影响呈分段常数。

有些场景会使某种类型的函数，比如对数函数或指数函数，成为合适的基函数 $h_m$。然而在更多的场景中，基拓展被视为一种更灵活的近似 $f(X)$ 的方法。多项式函数即为一个例子，但其在全局的性质也导致了其局限性：为了在某个区间达到某种函数形式的系数，可能使这个函数在其他区间上产生非常极端的曲线。本章介绍更可用的 **分段多项式（piecewise-polynomials）** 和 **样条（spline）** 类的允许局部多项式函数的方法。还会介绍 **小波（wavelet）** 基函数，在信号和图像模型中非常有效。基拓展方法会指定一个基函数的 **字典（dictionary）** $\mathcal{D}$，其中包含基函数的个数 $\|\mathcal{D}\|$ 非常大，大到无法用已有数据进行拟合。于是在使用字典中函数时，也必须使用某种控制模型复杂度的方法。下面为三个常见的方法：

* 函数限制，即预先限制可选函数的范围。例如限制加性函数，即假设模型需要满足
  $$\begin{align}
  f(X)&=\sum_{j=1}^p f_j(X_j) \\\\
      &=\sum_{j=1}^p\sum_{m=1}^{M_j} \beta_{jm}h_{jm}(X_j)\tag{5.2}
  \end{align}$$
  每个元素函数 $f_j$ 中使用的基函数个数 $M_j$ 控制了模型的复杂度。
* 函数选择，即自适应地在字典中寻找对模型拟合贡献最大的几个基函数 $h_m$。第三章中介绍的变量选择方法在此也适用。诸如 CART、MARS、和提升（boosting）方法等分段贪心算法也属于这个范畴。
* 正则化，即在使用整个字段的同时对系数采取约束。岭回归即为正则化方法的一个简单例子，而套索回归是同时正则化和变量选择的例子。本章会介绍正则化的一些更复杂的方法。

----------
### 内容概要
{{< list_children >}}

----------
### 本章练习


[^1]: 加性（additive）模型指的是 $f(X)$ 可分解为若干个元素 $f_j(X)$ 之和的形式。